{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 设计多种模型的文本分类试验，上传不同参数配置下的试验结果"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2522c0c2491a716b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "bayes分类(效果很差）\n",
    "\n",
    "分析原因： 1. 分类少 2. 数据太少？"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66c21ff59be1c15f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-01T08:11:25.649620Z",
     "start_time": "2024-03-01T08:11:23.867840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/44/bdwdgvls56gdjs1jzvrxf7q00000gn/T/jieba.cache\n",
      "Loading model cost 0.292 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify[0], prob[0.6663051639275882]\n",
      "classify[1], prob[0.3336948360724118]\n",
      "[['0', 0.6663051639275882], ['1', 0.3336948360724118]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "jieba.initialize()\n",
    "\n",
    "class BayesApproach:\n",
    "    def __init__(self, path):\n",
    "        self.p_class = defaultdict(int)\n",
    "        self.word_class_prob = defaultdict(dict)\n",
    "        self.load(path)\n",
    "        \n",
    "    def load(self, path):\n",
    "        self.class_name_to_word_freq = defaultdict(dict)\n",
    "        self.all_words = set()\n",
    "        with open(path, encoding=\"utf-8\") as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            next(csv_reader)\n",
    "            for row in csv_reader:\n",
    "                class_name = row[0]\n",
    "                content = row[1]\n",
    "                words = jieba.cut(content)\n",
    "                self.all_words = self.all_words.union(set(words))\n",
    "                self.p_class[class_name] += 1\n",
    "                # class_name_to_word_freq： 【class : [word1: 10, word2: 20】\n",
    "                word_freq = self.class_name_to_word_freq[class_name]\n",
    "                for word in words:\n",
    "                    if word not in word_freq:\n",
    "                        word_freq[word] = 1\n",
    "                    else:\n",
    "                        word_freq += 1\n",
    "        self.freq_to_prob()\n",
    "        return\n",
    "    \n",
    "    def freq_to_prob(self):\n",
    "        total_sample_count = sum(self.p_class.values())\n",
    "        # p_class: [class1: 0.2, class2: 0.8]\n",
    "        self.p_class = dict([c, self.p_class[c] / total_sample_count] for c in self.p_class)\n",
    "        self.word_class_prob = defaultdict(dict)\n",
    "        # class_name_to_word_freq: [class: [word1: 0.1, word2: 0.9]]\n",
    "        for class_name, word_freq in self.class_name_to_word_freq.items():\n",
    "            total_word_count = sum(count for count in word_freq.values()) #每个类别总词数\n",
    "            for word in word_freq:\n",
    "                prob = (word_freq[word] + 1) / (total_word_count + len(self.all_words))\n",
    "                self.word_class_prob[class_name][word] = prob\n",
    "            self.word_class_prob[class_name][\"<unk>\"] = 1 / (total_word_count + len(self.all_words))\n",
    "        return\n",
    "    \n",
    "    def get_words_class_prob(self, words, class_name):\n",
    "        result = 1\n",
    "        for word in words:\n",
    "            unk_prob = self.word_class_prob[class_name][\"<unk>\"]\n",
    "            result *= self.word_class_prob[class_name].get(word, unk_prob)\n",
    "        return result\n",
    "    \n",
    "    def get_class_prob(self, words, class_name):\n",
    "        #P(x1)\n",
    "        p_x = self.p_class[class_name]\n",
    "        # P(w1, w2..wn|x1) = P(w1|x1) * P(w2|x1)...P(wn|x1)\n",
    "        p_w_x = self.get_words_class_prob(words, class_name)\n",
    "        return p_x * p_w_x\n",
    "    \n",
    "    def classify(self, sentence):\n",
    "        words = jieba.lcut(sentence)\n",
    "        results = []\n",
    "        for class_name in self.p_class:\n",
    "            # P(w1, w2..wn|x1) * P(x1)\n",
    "            prob = self.get_class_prob(words, class_name)\n",
    "            results.append([class_name, prob])\n",
    "        results = sorted(results, key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "        # P(w1, w2, w3...wn) = P(w1,w2..Wn|x1)*P(x1) + P(w1,w2..Wn|x2)*P(x2) ... P(w1,w2..Wn|xn)*P(xn)\n",
    "        pw = sum([x[1] for x in results])\n",
    "        results = [[c, prob/pw] for c, prob in results]\n",
    "        \n",
    "        for class_name, prob in results:\n",
    "            print(\"classify[%s], prob[%s]\"%(class_name, prob))\n",
    "        return results\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    path = \"文本分类练习.csv\"\n",
    "    ba = BayesApproach(path)\n",
    "    query = \"味道很好，送餐快\"\n",
    "    result = ba.classify(query)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8cb575cb19a3ce5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# svm 分类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d872c0fac6ce0cd3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      7987\n",
      "           1       0.81      0.49      0.61      4000\n",
      "\n",
      "    accuracy                           0.79     11987\n",
      "   macro avg       0.80      0.72      0.74     11987\n",
      "weighted avg       0.80      0.79      0.78     11987\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jieba\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1 好评 0 差评\n",
    "LABELS = {\"1\": 1, \"0\": 0}\n",
    "\n",
    "#输入模型文件路径\n",
    "#加载训练好的模型\n",
    "def load_word2vec_model(path):\n",
    "    model = Word2Vec.load(path)\n",
    "    return model\n",
    "\n",
    "#tag标签转化为类别标号\n",
    "def label_to_label_index(labels):\n",
    "    return [LABELS[y] for y in labels]\n",
    "\n",
    "#文本向量化，使用了基于这些文本训练的词向量\n",
    "def sentences_to_vectors(sentences, model):\n",
    "    vectors = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        vector = np.zeros(model.vector_size)\n",
    "        for word in words:\n",
    "            try:\n",
    "                vector += model.wv[word]\n",
    "                # vector = np.max([vector, model.wv[word]], axis=0)\n",
    "            except KeyError:\n",
    "                vector += np.zeros(model.vector_size)\n",
    "        vectors.append(vector / len(words))\n",
    "    return np.array(vectors)\n",
    "\n",
    "def load_sentence(path, model):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(path, encoding=\"utf-8\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            labels.append(row[0])\n",
    "            sentences.append(\" \".join(jieba.lcut(row[1])))\n",
    "    train_x = sentences_to_vectors(sentences,model)\n",
    "    train_y = label_to_label_index(labels)\n",
    "    return train_x, train_y\n",
    "            \n",
    "            \n",
    "def main():\n",
    "    model = load_word2vec_model('model.w2v')\n",
    "    train_x, train_y = load_sentence(\"文本分类练习.csv\", model)\n",
    "    classifier = SVC()\n",
    "    classifier.fit(train_x, train_y)\n",
    "    test_x, test_y = load_sentence(\"文本分类练习_test.csv\", model)\n",
    "    y_pred = classifier.predict(test_x)\n",
    "    print(classification_report(test_y, y_pred))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T08:11:37.650052Z",
     "start_time": "2024-03-01T08:11:25.653245Z"
    }
   },
   "id": "483ea464b638476e",
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
