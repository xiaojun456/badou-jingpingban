# Week6作业说明  
## 在输入数据长度为4时的所有可训练参数罗列：  
```
word_embedding (vocab_len, 768) -> (21128, 768)  
position_embedding (512, 768)  
token_type_embedding (2, 768)  
embdddings_layer_norm_w (768, 1)  
embeddings_layer_norm_b (768, 1)  
  
q_w (768, 768)  
q_b (768, 1)  
k_w (768, 768)  
k_b (768, 1)  
v_w (768, 768)  
v_b (768, 1)  
attention_output_weight (768, 768)  
attention_output_bias (768, 1)  
attention_layer_norm_w (768, 1)  
attention_layer_norm_b (768, 1)  
intermediate_weight (3072, 768)  
intermediate_bias (3072, 1)  
output_weight (768, 3072)  
output_bias (768, 1)  
ff_layer_norm_w (768, 1)  
ff_layer_norm_b (768, 1)  
pooler_dense_weight (768, 768)  
pooler_dense_bias (768, 1)  
```
## 在作业代码中定义self.embeddings_weights存储embedding层的所有权重矩阵：  
```
self.embeddings_weights = [self.word_embeddings,
                           self.position_embeddings,
                           self.token_type_embeddings,
                           self.embeddings_layer_norm_weight,
                           self.embeddings_layer_norm_bias]
```  
## 定义self.all_para = []收集所有参数的size，计算总和存入self.para_counts:  
```
self.all_para = []
# embedding para
for p_e in self.embeddings_weights:
  self.all_para.append(p_e.size)
# transformer para
for p_t in self.transformer_weights[0]:
  self.all_para.append(p_t.size)
self.all_para.append(self.pooler_dense_weight.size)
self.all_para.append(self.pooler_dense_bias.size)
self.para_counts = sum(self.all_para)
```


